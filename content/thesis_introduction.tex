\chapter{Introduction}
\label{chap:introduction}

The Standard Model (SM) of particle physics has proven to be remarkably precise in its predictions over the last decades.
However, there are still some missing pieces, namely the intriguing nature of neutrinos.
Not only do their mass eigenstates mix with their flavour eigenstates but also are their masses smaller than the charged leptons by several orders of magnitude.
Measuring these effects is not simplified by the fact that the interaction rates (cross-section) of neutrinos are extremely small, raising the need for high-intensity sources along with extremely massive detectors.
This is the reason why it took almost \num{25} years from their proposal to the first measurement of neutrinos.
As of today, neutrino mixing is well-established and their masses have been proven to be non-zero.
The basis for this was the discovery of neutrino oscillations, a consequence of neutrino flavour mixing paired with non-zero masses.
However, there are still several unknowns in today's neutrino mixing and oscillation model.
In particular, the model contains three CP-violating phases that have yet to be measured.
The consequences of measuring CP-violation in neutrino oscillation could be far-reaching.
Via certain cosmological models, it could explain the asymmetry between matter and antimatter in the universe.
Besides, while it is certain that at least two out of the three neutrinos have non-zero masses, their ordering is still unknown.
Its determination will help to integrate massive neutrinos into the SM where they are currently massless.

Measuring the unknown parameters of the neutrino mixing and oscillation model will require a neutrino interaction sample of unprecedented size.
Much of today's knowledge was gained from neutrinos produced in the Sun and the Earth's atmosphere.
However, for future experiments, these and other natural sources are not intense and/or precise enough for the required measurements.
Therefore, artificially produced neutrino beams will be employed, paired with huge detectors.
Not only are neutrino interactions with matter very rare, they are also quite manifold, giving raise to the need for detectors capable of recording complex event topologies and reconstructing energies precisely.

\glspl{lartpc} are a prime candidate for the aforementioned requirements.
They combine a high-density target material with a high-precision 3D tracker and calorimeter.
The incoming neutrinos interact with the \lar{}, producing charged secondary particles which in turn ionise \ce{Ar} atoms.
By means of an electric field, the produced electron-ion pairs can be separated and drifted towards a two-dimensional charge readout.
A small remainder of pairs recombine and produce very prompt (\si{\nano\second}) UV scintillation light which can be used to determine the propagation time of the charge drifted towards the readout plane.
Due to the constant drift velocity of charge in a medium subject to an electric field, the distance from the ionisation location to the readout plane can be precisely determined.
Combined with the 2D information from the readout, the full 3D interaction topology can be reconstructed.

The \dune{} is a next generation long-baseline beam neutrino oscillation experiment, placing \lartpc{}s in an accelerator-produced muon neutrino beam.
Neutrino oscillations will be observed over a baseline of \SI{1300}{\kilo\metre}.
Several implications result from the required number of neutrino interactions to be sensitive to CP violation and neutrino mass ordering.
As mentioned above, a very intense neutrino beam and a large target mass are necessary.
However, this is not enough; at the same time, uncertainties have to be kept low.
Statistical uncertainties can be lowered by acquiring more neutrino interactions but this is not true for systematic uncertainties which will therefore become the limiting factor.
Systematic uncertainties have various sources, some of which can be exploited.
Two of the biggest contributors are the neutrino beam and the interaction model of neutrinos with matter.
Beam-related uncertainties can be eliminated partially by characterising the neutrino beam at the production location (in addition to replica targe experiments).
A \emph{near detector} will be placed in front of the beam facility in addition to the \emph{far detector} at the end of the baseline.
Many uncertainties cancel out by comparing the neutrino fluxes in the near and far detector.
To some extent, uncertainties related to the interaction model cancel out as well if the same target material is used in both detectors.
Finally, using the same technology in both detectors, cancels even more of the remaining uncertainties.
Therefore, the near detector complex needs to contain a \lartpc{} component.

Up until now, \lartpc{} charge readouts have been realised by means of multiple one-dimensional wire planes---the last of them collecting the charge while the previous ones register the induced voltage pulse by the passing charge---due to technological limitations.
Combined with the time of the drifting charge, this results in one 2D image of the event topology per wire plane, effectively reducing the 3D capabilities of the \gls{tpc} to multiple 2D projections.
Additionally, \lartpc{}s are comparatively slow detectors.
The minimum drift time of charge in \lar{} (and thus the readout time) is limited to $\order{\SI{1}{\milli\second\per\metre}}$ by constraints on the maximum cathode voltage.
Both the above have not prevented the huge success of \lartpc{}s up to now.
Due to the low interaction cross-section, event rates in current-generation \lartpc{}s have been low enough to cope with.
While this still applies to the \dune{} far detector, it is certainly not true for the near detector.
The high-intensity neutrino beam will result in event rates in the near detector significantly higher than what contemporary \lartpc{}s have been exposed to.
Even worse, the beam is delivered in very short pulses of very high intensity.
Because these pulses are one to two orders of magnitude shorter than a typical \lartpc{} readout cycle, the detector registers several neutrino interactions simultaneously, so-called event pile-up.
Combined with the 2D projection readout, this leads to significant difficulties in event reconstruction: disentangling the 3D interaction topologies from the recorded 2D projections.

An obvious solution to this challenge is to regain true 3D information from the \gls{tpc} by replacing the projective 1D wire planes with a true 2D pixelated charge readout.
However, as mentioned above, this is linked to technological challenges.
Replacing a two plane wire readout with pixels of the same pitch squares the number of required readout channels.
For the \lartpc{} in the \dune{} near detector complex with a size of \SI{4 x 5 x 2.5}{\metre}, this amounts to $\order{\num{e6}}$ cables needing to be routed out of the cryogenic vessel housing the detector.
The number of cable feedthroughs can be reduced by digitising charge readout waveforms inside the \lar{} and using high-speed digital links to aggregate many readout channels on a single cable.
However, this is far from trivial.
Besides the challenge of adapting existing electronics to the cryogenic temperatures of liquid argon, heat production has to be kept to a minimum to prevent the \lar{} from boiling.
While such electronics have already been designed for the wire-equipped far detectors, the former are not suitable for a pixelated near detector due to their power dissipation.

In addition to these readout issues, future large \lartpc{}s face several other challenges.
In particular for the high voltage (HV) and light readout systems.
Earlier studies at the University of Bern showed that the dielectric strength of liquid argon is much lower than predicted by studies performed in the fifties.~\cite{breakdown_14, swan1, swan2}
Again, this could be tolerated in contemporary detectors but will become a serious problem for future experiments.
Electronegative impurities present in the \lar{} result in a finite charge lifetime.
This results in a lower limit on the required drift field and therefore cathode voltage.
Due to the finite dielectric strength of \lar{}, the fraction of dead volume required around the cathode scales with detector size unless this is accounted for by a modified high voltage system of the detector.

In order to get proper timing for the third coordinate, the scintillation light flashes need to be matched to the correct events.
This becomes problematic in large monolithic \lartpc{} in high-pile-up environments.

The goal of this work is to establish the key technologies enabling the successful deployment of a \lartpc{} component in the \dune{} near detector complex.
A introduction to the history and theory of neutrino detection, as well as an overview of \dune{} are given in Chapter~\ref{chap:nu-detection}.

Chapter~\ref{chap:studies} contains several studies addressing the challenges met by future \lartpc{}s.
These include a thorough investigation of dielectric breakdowns in \lar{}, the development of new charge and light readout methods, as well as the evaluation of electronics for pixelated charge readouts.

The high voltage studies include high-speed footage, current-voltage characteristics and spectrometry of the breakdowns.
As a result, a hypothesis was developed providing a conclusive explanation of the phenomenon.
In addition, a technique was developed to increase the dielectric strength of \lar{} by an order of magnitude by means of a polymer coating.
However, the latter is not suitable for physics experiments as it fails to withstand multiple thermal cycles and loses its protection after a breakdown.
A new light readout based on Silicon PhotoMultipliers (SiPMs), \AL{}, developed by the University of Bern was tested as well.
The active area of the SiPMs is drastically increased by coupling them to a light trap formed of a combination of a dichroic filter with a WaveLength Shifter (WLS).
This makes it competitive to classical PM tubes for large area coverage while requiring a much reduced dead volume.

The main contribution to the \dune{} near detector complex is the demonstration of a pixelated \lartpc{}.
Conventional room-temperature digitisers were combined with analogue multiplexing due to the as yet lacking cryogenic electronics.
Several days of cosmic muon data were collected with a test stand designed and built at the University of Bern.
A software framework was written to reconstruct 3D tracks from the data.
Even though the employed pixelated readout yields 3D information on charge deposition in the \lartpc{}, the necessary analogue multiplexing introduced a certain amount of ambiguity.
The latter had to be resolved by the reconstruction algorithm.
Finally, the unambiguous positional information was fed to a Kalman filter.
This propagates a cosmic muon hypothesis through all the detector measurements taking into account the various involved charge deposition mechanisms in \lar{}.
The end result is a completely reconstructed particle track through the detector.
The combination of all the R\&D presented in this thesis resulted in the development of the \AC{}, a next-generation \lartpc{} concept, at the University of Bern.
It aims to address the most important challenges met by future \lartpc{}s.
The problematic high fields at the cathodes as well as the scintillation light containment issue are addressed by splitting up the detector into smaller ($\order{\SI{1}{\metre}}$), self-contained \glspl{tpc} sharing a common \lar{} bath.
A pixelated charge readout makes the detector capable of true 3D event recording.
To keep the dead volume to a minimum, \AL{} is used as the light readout system.
All of this is described in Chapters~\ref{chap:ac}.

Chapter~\ref{chap:dune-nd} introduces the proposed \AC{} \lartpc{} component for the \dune{} near detector complex together with a feasibility study of a \lartpc{} in such an environment.
Combining the knowledge gained from Chapter~\ref{chap:ac} with the next-generation pixel electronics briefly described in Chapter~\ref{chap:studies}, enables the realisation of a true 3D \lartpc{}.
However, it remains to be shown that such a detector is actually able to cope with the event rates expected in the near detector.
To assess this capability, a metric was needed representative of the physics processes.
Electromagnetic (EM) showers produced from the photons originating from \Pgpz decays are notoriously complex to reconstruct.
On the other hand, it is important to get their energy reconstruction right in order not to skew the neutrino energy spectrum because they are present in a significant fraction of the neutrino interaction expected in \dune{}.
At the \dune{} energies, EM showers deposit a plethora of apparently unconnected charge clusters in a \lartpc{} rather than a homogeneous cone.
Associating all those separate charge blobs to the correct event is one of the most difficult reconstruction tasks, even for a \lartpc{}.
Therefore, this type of EM shower was chosen for this study.
A rather rudimentary algorithm was employed to assign the deposited charge to the correct EM shower because all available \lartpc{} reconstruction algorithms are optimised for wire readouts.
The amount of misidentified charge from other events is a suitable metric to assess the impact of pile-up on the near detector physics.

Chapter~\ref{chap:conclusion} concludes the thesis.
